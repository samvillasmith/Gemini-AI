{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70828b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sam Ben-Yosef\\Desktop\\Gemini AI\\genaivenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ea2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6de3fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/veo-3.0-fast-generate-preview\n",
      "models/gemini-2.5-flash-preview-native-audio-dialog\n",
      "models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7270c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-2.5-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0dc7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the capital of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "748cf8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(prompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dec9095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.generativeai.types.generation_types.GenerateContentResponse"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4f79d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"The capital of France is **Paris**.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 8,\n",
       "        \"candidates_token_count\": 8,\n",
       "        \"total_token_count\": 372\n",
       "      },\n",
       "      \"model_version\": \"gemini-2.5-pro\"\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22c096e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ef13fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_feedback: \n",
      "candidate[0] finish_reason: 1\n",
      "usage: prompt_token_count: 8\n",
      "candidates_token_count: 8\n",
      "total_token_count: 372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show whether the prompt was blocked\n",
    "print(\"prompt_feedback:\", response.prompt_feedback)  # will print None if allowed\n",
    "\n",
    "# Usual way to inspect the result state\n",
    "for i, c in enumerate(response.candidates):\n",
    "    print(f\"candidate[{i}] finish_reason:\", c.finish_reason)\n",
    "    try:\n",
    "        # Safety ratings are present even when not blocked\n",
    "        for r in getattr(c, \"safety_ratings\", []) or []:\n",
    "            print(\" -\", r.category, r.probability)\n",
    "    except Exception as e:\n",
    "        print(\" - no safety_ratings:\", e)\n",
    "\n",
    "# Token usage (helpful “feedback” about cost/length)\n",
    "print(\"usage:\", response.usage_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "812b6832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[content {\n",
       "  parts {\n",
       "    text: \"The capital of France is **Paris**.\"\n",
       "  }\n",
       "  role: \"model\"\n",
       "}\n",
       "finish_reason: STOP\n",
       "index: 0\n",
       "]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b1a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is **Paris**.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18cb4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a haiku about generative AI.\"\n",
    "response = model.generate_content(prompt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3171364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data learns to dream,\n",
      "Weaving worlds from whispered words,\n",
      "A new mind awakes.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e729939",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a haiku about conversational AI companions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded24740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt):\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12bf009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A voice made of code\n",
      "Answers in the quiet room,\n",
      "I am not alone.\n"
     ]
    }
   ],
   "source": [
    "haiku = get_response(prompt)\n",
    "print(haiku)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaivenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
